{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eff6512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b260ca4",
   "metadata": {},
   "source": [
    "1. 可以自己客製化自己的 loader，寫好 extract 的格式即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc850ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc ID: 8a919def-6d6c-413a-a7c2-12b4ba6eaee3\n",
      "Text: Context LLMs are a phenomenal piece of technology for knowledge\n",
      "generation and reasoning. They are pre-trained on large amounts of\n",
      "publicly available data. How do we best augment LLMs with our own\n",
      "private data? We need a comprehensive toolkit to help perform this\n",
      "data augmentation for LLMs.  Proposed Solution That's where LlamaIndex\n",
      "comes in. Ll...\n"
     ]
    }
   ],
   "source": [
    "example_doc = Document.example()\n",
    "print(example_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "460661cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context\n",
      "LLMs are a phenomenal piece of technology for knowledge generation and reasoning.\n",
      "They are pre-trained on large amounts of publicly available data.\n",
      "How do we best augment LLMs with our own private data?\n",
      "We need a comprehensive toolkit to help perform this data augmentation for LLMs.\n",
      "\n",
      "Proposed Solution\n",
      "That's where LlamaIndex comes in. LlamaIndex is a \"data framework\" to help\n",
      "you build LLM  apps. It provides the following tools:\n",
      "\n",
      "Offers data connectors to ingest your existing data sources and data formats\n",
      "(APIs, PDFs, docs, SQL, etc.)\n",
      "Provides ways to structure your data (indices, graphs) so that this data can be\n",
      "easily used with LLMs.\n",
      "Provides an advanced retrieval/query interface over your data:\n",
      "Feed in any LLM input prompt, get back retrieved context and knowledge-augmented output.\n",
      "Allows easy integrations with your outer application framework\n",
      "(e.g. with LangChain, Flask, Docker, ChatGPT, anything else).\n",
      "LlamaIndex provides tools for both beginner users and advanced users.\n",
      "Our high-level API allows beginner users to use LlamaIndex to ingest and\n",
      "query their data in 5 lines of code. Our lower-level APIs allow advanced users to\n",
      "customize and extend any module (data connectors, indices, retrievers, query engines,\n",
      "reranking modules), to fit their needs.\n"
     ]
    }
   ],
   "source": [
    "content = example_doc.get_content()\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "766f7b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llama_index.core.schema.Document"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(example_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd8fe529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "868cd08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='8a919def-6d6c-413a-a7c2-12b4ba6eaee3', embedding=None, metadata={'filename': 'README.md', 'category': 'codebase'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='\\nContext\\nLLMs are a phenomenal piece of technology for knowledge generation and reasoning.\\nThey are pre-trained on large amounts of publicly available data.\\nHow do we best augment LLMs with our own private data?\\nWe need a comprehensive toolkit to help perform this data augmentation for LLMs.\\n\\nProposed Solution\\nThat\\'s where LlamaIndex comes in. LlamaIndex is a \"data framework\" to help\\nyou build LLM  apps. It provides the following tools:\\n\\nOffers data connectors to ingest your existing data sources and data formats\\n(APIs, PDFs, docs, SQL, etc.)\\nProvides ways to structure your data (indices, graphs) so that this data can be\\neasily used with LLMs.\\nProvides an advanced retrieval/query interface over your data:\\nFeed in any LLM input prompt, get back retrieved context and knowledge-augmented output.\\nAllows easy integrations with your outer application framework\\n(e.g. with LangChain, Flask, Docker, ChatGPT, anything else).\\nLlamaIndex provides tools for both beginner users and advanced users.\\nOur high-level API allows beginner users to use LlamaIndex to ingest and\\nquery their data in 5 lines of code. Our lower-level APIs allow advanced users to\\ncustomize and extend any module (data connectors, indices, retrievers, query engines,\\nreranking modules), to fit their needs.\\n', mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a21fd3",
   "metadata": {},
   "source": [
    "## 製作範例：\n",
    "```\n",
    "import json\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import JSONNodeParser\n",
    "```\n",
    "### 1. 您的原始資料\n",
    "json_data = { ... } # 您的 JSON 內容\n",
    "\n",
    "### 2. 封裝成 Document 並放入 Metadata\n",
    "```\n",
    "doc = Document(\n",
    "    text=json.dumps(json_data, ensure_ascii=False),\n",
    "    metadata={\n",
    "        \"file_name\": \"cathay_social_dashboard.json\",\n",
    "        \"category\": \"social_media_analysis\",\n",
    "        \"author\": \"yu yuna\", # 參考您的報告作者 \n",
    "        \"data_year\": \"2022\"  # 參考您的資料區間 \n",
    "    }\n",
    ")\n",
    "```\n",
    "### 3. 餵給 Parser\n",
    "```\n",
    "parser = JSONNodeParser()\n",
    "nodes = parser.get_nodes_from_documents([doc])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c7c0eb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "707efa39",
   "metadata": {},
   "source": [
    "為了確保切分後的 Node 更好用，建議在 metadata 設定中加入以下控制：\n",
    "\n",
    "排除不必要的 Metadata 出現於 Text 中： \n",
    "如果您不想讓 author 這種資訊出現在 LLM 閱讀的 text 區塊中（浪費 token），可以設定：\n",
    "```\n",
    "doc.excluded_llm_metadata_keys = [\"author\", \"file_name\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbb69da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-embeddings-huggingface in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (0.4.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.27.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from llama-index-embeddings-huggingface) (0.12.9)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from llama-index-embeddings-huggingface) (3.3.1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.11.11)\n",
      "Requirement already satisfied: dataclasses-json in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2024.12.0)\n",
      "Requirement already satisfied: httpx in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.9.1)\n",
      "Requirement already satisfied: numpy in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.10.4)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.17.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.10)\n",
      "Requirement already satisfied: filelock in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.16.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.2)\n",
      "Requirement already satisfied: click in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (2024.12.14)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.47.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: scipy in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.15.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.1.1)\n",
      "Requirement already satisfied: jinja2 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (3.23.2)\n",
      "Requirement already satisfied: anyio in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.0.7)\n",
      "Requirement already satisfied: sniffio in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-embeddings-huggingface) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1f2536a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.8-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from ipywidgets) (8.31.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.15-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: decorator in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack_data in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: wcwidth in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading ipywidgets-8.1.8-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.16-py3-none-any.whl (914 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m914.9/914.9 kB\u001b[0m \u001b[31m756.6 kB/s\u001b[0m  \u001b[33m0:00:01\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading widgetsnbextension-4.0.15-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m eta \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [ipywidgets]\n",
      "\u001b[1A\u001b[2KSuccessfully installed ipywidgets-8.1.8 jupyterlab_widgets-3.0.16 widgetsnbextension-4.0.15\n"
     ]
    }
   ],
   "source": [
    "! pip3 install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b47151a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dingtseng/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-m3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a9cbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_test = embed_model.get_text_embedding(\"這是一堂關於LlamaIndex的教學課程\")\n",
    "emb_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a106db69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "documents = SimpleDirectoryReader(input_dir=\"./data/json\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83719b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='46336f3f-8870-4069-b3d1-f0fa810ae5b8', embedding=None, metadata={'file_path': '/Users/dingtseng/Documents/python_rag_class/demo_1/llamaIndex-tutorial/data/json/techorange-2024-10-16.json', 'file_name': 'techorange-2024-10-16.json', 'file_type': 'application/json', 'file_size': 40751, 'creation_date': '2025-12-18', 'last_modified_date': '2025-01-03'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='[\\n    {\\n        \"title\": \"【台灣陷入尷尬處境】半導體耗電量狂飆又得淨零轉型，核電會是最佳解？\",\\n        \"content\": \"台灣企業滿足了全球高達 68% 的晶片製造供應，隨之而來的是大量能源需求——根據綠色和平組織的預測，2030 年台灣半導體製造產業之耗電量，將會相當於 2021 年紐西蘭全島的耗電量的兩倍，其中將有 82% 的需求來自台積電。\\\\n台灣為何陷入能源危機、與淨零目標遙遙無期？\\\\nAI 時代用電激增，台灣卻在此時面臨牽涉到國安、氣候、政治挑戰的能源困境：台灣全島有高達 9 成的用電量靠的是進口石化燃料；兩岸情勢也持續緊繃，台灣必須面對來自中國的經濟封鎖、國際孤立，甚或武力入侵威脅；而出於政治考量，執政黨主張在 2025 年前告別核電，打造「非核家園」，並在同一年達成「燃煤發電 30%、天然氣發電 50%、再生能源 20%」的能源結構目標。\\\\n再者，政府還訂立野心勃勃的潔淨能源目標，包含遵循巴黎協議，2030 年台灣將減碳 23%，並在 2050 年前達成淨零碳排；私部門方面，包含台積電在內的多家大廠，都簽署了 RE100 全球再生能源倡議，承諾於 2050 年前採用 100％ 綠電。\\\\n目前看來，沒有任何一絲達標跡象，現實和理想之間尚存在著難以跨越的鴻溝。\\\\n台灣現行能源結構十分脆弱，極度仰賴進口\\\\n根據經濟部統計，去年台灣有 83% 的用電需求仰賴石化燃料，其中煤炭發電佔 42%、天然氣佔 40%、石油佔 1%，另外核能佔 6%，而太陽能、風力、水力、生質能發電加總起來也才佔 10%。\\\\n這樣的能源供應系統極不穩定，因為燃料進口隨時面臨到國際價格波動或中國封鎖的風險；即便台灣政府能出手調整電價，卻也造成台電債台高築，而一旦中國海軍封鎖台灣海峽，台灣島約只有 6 週的煤炭儲備量，以及約 1 週的液化天然氣儲備量。\\\\n縱使上述風險都尚未發生，今年台灣發電的備轉容量已多次掉到 5%（理想的系統備轉容量為 25%），且在過去 8 年內，就發生過 4 次大規模跳電，限電情況也不少見，在在顯示出台灣供電困境亟待解決。\\\\n再生能源為何進展緩慢？專家警告外資出走可能性\\\\n由於台灣國土面積小且山地多，太陽能發電面臨土地取得不易的限制。離岸風電雖大有潛力，但近年受到政府欲扶植在地產業發展的政策限制，只能運用 MIT 產品和聘用台灣勞工，礙於技術落差，造成不必要的成本支出與工程延宕；另一方面，港口腹地小、風力發電機直接位於中國飛彈射程範圍內，海底電纜在軍事衝突中高度脆弱，這些都構成台灣再生能源之發展困境。\\\\nNicholas Chen 是一位長期研究台灣氣候與能源政策的律師，他認為台灣必須為潔淨能源的發展路徑做出大幅調整，否則可能將面臨外資出走的危機——有越來越多企業需要淨零排放的生產環境，以滿足如亞馬遜、Meta、Google 等合作夥伴的淨零承諾，同時避免碳排相關的貿易壁壘，例如歐盟的碳邊境調整機制（CBAM）。（編按：Google、AWS、微軟目前皆有在台灣設立資料中心。）\\\\n核電重啟再掀討論，但是否為最佳解？\\\\n針對當前的能源危機，經濟部能源署副署長吳志偉表示：「立法院裡的辯論還在持續，因為社會大眾既渴望非核家園被逐步實現，又想看到碳排量減少，因此開始有人探討當其他條件齊備，關閉的核電廠是否有重啟的可能性。」\\\\n為此，Nicholas Chen 指出「唯有核能才是可擴展的再生能源」，科技部顧問 Peter Kurz 則進一步指出，台灣的能源困境需要跳脫框架的解決方案，有鑑於海底電纜的脆弱性，且核能電廠容易受地震威脅，另一項執政黨可能考慮的做法，是能離岸運作的小型模組化的核反應爐。\\\\n話雖如此，一項史丹佛大學的研究發現，小型核反應爐將使核廢料處置更加棘手。該研究測試了三座反應爐，發現所造成的放射物質「鈽」，其一萬年後的放射性將比傳統核電廠高 50% 以上。\\\\n台灣作為全球最大的先進晶片製造國，國內電力供不應求，高度仰賴進口燃料，即將關閉最後一座核電廠，再生能源發展又遲緩，朝野如何協商出妥善的應對措施，確保能源供應穩定，已是刻不容緩的議題。\\\\n【推薦閱讀】\\\\n◆ 【碳費上路】全國徵收對象達 500 家！政府打算怎麼使用收到的 60 億？\\\\n◆ 改善工業能源效率從何做起？報告揭 3 大行動每年全球一起省下 2 兆美元\\\\n◆ WEF 「燈塔工廠」公布！鴻海揭拿下 2 座燈塔工廠背後關鍵技術\\\\n＊本文開放合作夥伴轉載，參考資料：《Yale Environment 360》、Stanford，首圖來源：Shutterstock。\\\\n（責任編輯：廖紹伶）\"\\n    },\\n    {\\n        \"title\": \"Google 簽下協議買核電，建 7 座小型反應爐為 AI 與環保需求\",\\n        \"content\": \"Google 宣布與能源新創公司 Kairos Power 簽下協議，將於未來興建 7 座小型模組化核反應爐（SMR），為 AI 運算提供充足電力，並且藉由核能以應對越來越嚴格的環保要求。\\\\nGoogle 表示，為了實踐、開發與商業化先進的潔淨能源技術，並且為全球資料中心和辦公室提供電力，未來將把核能發電當成太陽能、風能等再生能源的補充，使企業逐步朝無碳能源與淨零目標持續邁進。\\\\nGoogle 目標取得 500MW 核能容量\\\\n根據美國能源部數據，核電在所有發電來源中具有最高的經濟效益，甚至可以創造出高薪、長期的就業機會；美國能源部估計，2050 年美國當地的先進核電裝置，容量將達到 200GW，並預期對外多達 375000 名勞工。\\\\nGoogle 與 Kairos Power 希望達成的目標，為 2030 年之前將第一個小型模組化核反應爐正式投入運行，接著於 2035 年前完成更多部署；Google 預計，Kairos Power 最終將有 7 座 SMR 上線運轉，並且為公司提供 500MW 容量的核能電力。\\\\n無論 Google 與 Kairos Power 皆沒有明確指出，究竟雙方這項合作投資將花費多少資金，也沒有透露發電廠將建設於美國何處。\\\\n採用 SMR 小型反應爐，填補發電缺口\\\\nGoogle 表示，Kairos Power 目前在開啟長期商業化之路上，已經取得多個技術里程碑，例如今年夏天，Kairos Power 於美國田納西州的示範型 Hermes 無動力反應器即正式破土興建，為美國第一個獲得核能管理委員會（NRC）建設許可的先進反應爐計畫。\\\\nKairos Power 的 SMR 採用熔鹽冷卻系統，結合球床反應爐設計，可以有效將熱能傳送至蒸氣渦輪進行發電；此被動式安全系統可以讓反應堆在低壓力下運作，使核子反應爐的設計變得更為簡單，甚至更加經濟實惠。\\\\n根據高盛估計，美國資料中心的用電量預計在 2023 年至 2030 年間將增加 2 倍，也就是出現了高達 47GW 的發電容量缺口。\\\\n應對環保需求，科技巨頭紛紛擁抱核能\\\\n為了滿足 AI 帶來不斷增長的電力需求，如 Amazon、微軟等科技巨頭，紛紛將眼光投向核能，例如後者就與星座能源（Constellation Energy）合作，計畫重啟三哩島核電廠。\\\\n根據分析，Kairos Power 未來還需要獲得 NRC 批准，才有辦法啟動發電廠相關設計與施工，若再加上取得當地監管機關的授權和允許，各種行政流程加起來，可能就得花上至少數年時間。\\\\n反對人士則批評，SMR 的製造成本預期會非常昂貴，並且無法大規模投入以實現規模化經濟，同時核廢料該如何處置，亦成為了美國必須面對的問題。\\\\n【推薦閱讀】\\\\n◆ 公佈了！台灣碳費高過中日韓，前經濟部長點 3 大產業迎財務衝擊\\\\n◆ 微軟想重啟三哩島核電廠為 AI 供電，專家分析至少有 3 大困難\\\\n◆ AI 電力需求激增 160%，黃仁勳、奧特曼、Google 史無前例進入白宮要能源\\\\n＊本文開放合作夥伴轉載，資料來源：《Reuters》、《Google》。首圖來源：Google\"\\n    },\\n    {\\n        \"title\": \"蘋果策略大轉彎？傳放棄每年更新產品，VR 挫敗考慮推智慧眼鏡\",\\n        \"content\": \"根據蘋果記者 Mark Gurman 近來的爆料，他指出蘋果正在考慮放棄每年更新旗下產品，不再強制遵守原先的升級週期，蘋果下一步也將轉攻智慧家庭市場，對抗 Google 與 Amazon，同時 Vision Pro 平價版最快明年就能登場，智慧眼鏡也是未來蘋果將關注的重大目標。\\\\n蘋果產品更新開始打破規律\\\\nMark Gurman 表示，長期以來蘋果（Apple）年年都會發表新產品，外界基本上已經適應了該公司的規律，比方說先在 6 月開發者大會（WWDC）上預覽新系統、新軟體，然後於 9 月、10 月分別推出配套設備，像是 iPhone、iPad 和 Mac。\\\\n雖然說蘋果的規律性作法有不少好處，例如讓員工先擁有心理預期，確定某些產品究竟何時該準備就緒，以及讓分析師、投資者明白未來會發生什麼事，但這個戰略卻也開始出現了缺陷。\\\\nMark Gurman 說，蘋果手上目前握有的產品線，包括多款 iPhone、iPad、Mac 和 AirPods，但想要每年更新大多數產品，事實上有些不切實際；此外，有些產品如 Apple Watch Ultra 或 iPhone SE，其實也不需要太過頻繁的常態性更新。\\\\n因此近兩年來，蘋果開始打破原先規律，例如在今年 5 月的春季發表會上，更新 iPad Air、iPad Pro，並發表全新的 Apple M4 晶片；此外，Apple M3 晶片版本的 MacBook Air，更是於今年 3 月突襲登場。\\\\niPhone 仍會維持年年升級\\\\n除了硬體產品之外，蘋果還擁有一系列作業系統，包含 iOS、macOS、visionOS、watchOS、tvOS 和 iPadOS，以及在 AirPods 與其他智慧家庭設備上運行的軟體；在硬體加上軟體的多元產品線下，蘋果想要像過去一樣，按時把所有東西準備好並交給消費者，已經變得十分困難。\\\\n因此 Mark Gurman 認為，儘管出於競爭、財務和行銷原因，未來蘋果或許還是會維持每年發表一款新 iPhone 的頻率，但其他產品就不見得會獲得頻繁升級，藉此減少軟體與硬體之間的割裂與尷尬，避免遭外界批評系統更新後根本沒有新功能，例如近期推出的 iPadOS 18。\\\\n蘋果下一步強攻智慧家庭\\\\n除了產品更新頻率的變動外，蘋果預期也會開始朝智慧家庭生態系進行猛攻。Mark Gurman 表示，他預測接下來的兩年內，智慧家庭硬體將成為蘋果的主軸，並指出該公司將會開發出新的作業系統 homeOS 及智慧顯示器，甚至不排除推出更高階的居家機器人，搶占智慧家庭市場。\\\\nMark Gurman 指出，若蘋果的智慧家庭硬體想取得成功，就必須支援盡可能多的配件，即藉由提前布局的 Matter 的智慧家庭協議，讓 Amazon、Google 和蘋果設備進行協同工作，打破原先堅持的封閉生態系統。\\\\n另一個推動蘋果發展智慧家庭的因素則是人工智慧。蘋果預期將利用 Apple Intelligence 平台，提供更強大的家庭自動化工具，以及對應用程式、裝置和媒體內容的精確控制。AI 預期也將被應用在消費者與產品之間的互動上，例如感知誰在觀看螢幕、人們在做什麼及誰在說話。\\\\nVision Pro 受挫，智慧眼鏡 2027 登場\\\\n至於在空間運算方面，受到外界批評的 Vision Pro，由於太重、太貴，似乎注定只能成為一款小眾產品，反觀 Meta Ray-Ban 智慧眼鏡，以更輕盈、更便宜的姿態取得了成功，這或許會加速蘋果推出平價款 Vision Pro 的速度，Mark Gurman 預測該產品明年第二季就能上市。\\\\n此外，配備更快晶片的第二代 Vision Pro 預期將於 2026 年上市，到了 2027 年，蘋果則會考慮推出與 Meta Ray-Bans 智慧眼鏡類似的產品，以及內建攝影鏡頭的 AirPods。\\\\nMark Gurman 說，蘋果目前面臨的更大問題，在於該公司推出新技術的速度依然太慢，幾乎都是在追逐其他的腳步，甚至包含人工智慧領域在內。\\\\n【推薦閱讀】\\\\n◆ 蘋果 AI 收費遇 1 困難，分析師指獲利仍靠硬體 iPhone 將漲價\\\\n◆ 祖克柏抨擊蘋果「追求完美」錯過機會，Meta 將與蘋果互戰十年\\\\n◆ Google 被罰 850 億、追蘋果 4600 億欠稅，歐盟為什麼向科技巨頭大開殺戒？\\\\n＊本文開放合作夥伴轉載，資料來源：《Bloomberg》、《PhoneArena》。首圖來源：Apple\"\\n    },\\n    {\\n        \"title\": \"【碳費上路】全國徵收對象達 500 家！政府打算怎麼使用收到的 60 億？\",\\n        \"content\": \"環境部長彭啟明 14 日到立法院社福環衛委員會專題報告「台灣的碳費收費標準決議」，會中有多位立委關心未來徵收碳費如何「專款專用」，何時公布地方分配標準。彭啟明表示，溫室氣體管理基金管理會下次開會即會討論，最快明年會公布碳費使用的分配比例及標準，但也放心不會是大撒幣。\\\\n年碳排量逾 2.5 萬噸有 500 家，首年徵收達 60 億元\\\\n環境部上週預告的明年起碳費徵收對象裡，針對達到年排碳量 2.5 萬噸以上的排放源，全國總共 500（廠）家。環境部估算，2026 年若順利徵收，第一年約可收入新台幣\\xa060 億元。\\\\n在 500 家排放源裡，高雄即占 103 家。立委蘇清泉質詢表示，很多高污染行業的工廠設在高雄、屏東，是地方該減碳，但總公司在台北，繳稅大多繳給台北市。碳費日後要如何補助地方，確實做到落實減碳，希望環境部能說清楚。\\\\n立委柯志恩則強調，高雄排碳量占全國 20％，企業要繳交碳費非常高，當地高碳排、高污染、高碳費，到底有多少比例碳費回饋給地方，並保障產生高污染的地方能得到適度分配，環境部若要拖到明年才討論會不會太慢？\\\\n立委王育敏建議，行政院應提供環境部、經濟部更多資源來落實減碳，碳費要「專款專用」，必須由中央和地方一起來討論及制訂標準，除考量徵收來源比例，並要優先強化排碳大戶周邊減碳設施跟設備，開放地方政府透過計畫申請，各地經發局輔導企業落實減碳，才能達到雙贏。\\\\n立委廖偉翔指出，聯合國氣候峰會（COP27）公布台中火力發電廠碳排污染全球第 19 名，碳排 3419 萬噸，相當於紐西蘭全國一年的碳排量，台中市民是中火空污的最大受害者，且 COP28 指出，國家減碳目標要納入地方政府參與，建議碳費收入應比照空污基金的補助比例，6 成地方、4 成中央。\\\\n面對立委建議，環境部如何回應？\\\\n綜合幾位立委的建議，彭啟明表示，碳費的分配標準的確需要中央和地方一起來討論及制訂，跨部會的討論落實減碳，才會是「雙贏」。他表示，溫管基金明年開會時即會討論該項議題，最快明年會公布碳費使用的分配標準，也不會是「大撒幣」。\\\\n【推薦閱讀】\\\\n◆ 改善工業能源效率從何做起？報告揭 3 大行動每年全球一起省下 2 兆美元\\\\n◆ WEF 「燈塔工廠」公布！鴻海揭拿下 2 座燈塔工廠背後關鍵技術\\\\n◆ 公佈了！台灣碳費高過中日韓，前經濟部長點 3 大產業迎財務衝擊\\\\n＊ 本文經合作夥伴 鉅亨網 授權轉載，並同意 TechOrange 編寫導讀與修訂標題，原文標題為〈〈碳費上路〉首年估收60億地方怎麼分？彭啟明：明年拍板分配標準不會大撒幣〉。首圖來源：鉅亨網。\\\\n（責任編輯：廖紹伶）\"\\n    },\\n    {\\n        \"title\": \"【10/15 快訊 Top 5】台積電稱「沒有新計畫」否認歐洲擴廠，將專注當前全球佈局\",\\n        \"content\": \"今天，《TechOrange》同樣精選出 5 則國內外科技新聞大事，讓你掌握科技動態不漏接！\\\\n＊ 台積電否認海外投資新計畫\\\\n國科會主委吳誠文近日接受外媒體專訪時表示，台積電日前開始於德國德勒斯登興建第 1 座晶圓廠，後續還會規劃幾座針對不同市場類別的晶圓廠，但台積電卻指出，企業目前正專注於現有的全球布局專案，暫時還沒有新的海外投資計畫。\\\\n台積電與博世、英飛凌及恩智浦，在歐洲合資成立 ESMC，並於今年 8 月 20 日舉行動土典禮，起建位於德國德勒斯登的首座晶圓廠；ESMC 預計將採用台積電的 28、22 奈米平面互補金屬氧化物半導體（CMOS），以及 16、12 奈米鰭式場效電晶體（FinFET）製程技術，估計月產能將達 4 萬片 12 吋晶圓。\\\\n＊ 產官學結合，成台灣半導體最大力量\\\\n國科會主委吳誠文表示，台灣半導體業之所以發展成功，關鍵在於政府開發、經營與管理科學園區所下的功夫；此外，科學園區與在地大學、研究機構緊密相互合作，以及產業發展方向跟政策的規劃，環環相扣成為最大力量。\\\\n吳誠文說，由政府、學研界、半導體產業緊密結成的鐵三角，形成了一個堅固的發展力量。台灣在有限資源的限制下，創造出了半導體的榮景，未來不排除可以將類似模式擴展到全世界，協助全球各地建立成功的半導體產業。\\\\n＊ 新台幣 100 億額度，數發部端 AI 新創方案\\\\n數發部長黃彥男近日指出，發展 AI 需要技術、人才、產業資源互相配合，在台灣中小企業居多且資本有限的情況下，更需要政府介入輔導，因此數位發展部將補助計畫，預計額度達新台幣 100 億元，今年底即會公布細節，明年就可發動投資。\\\\n黃彥男直言，發展 AI 的第一步就是資金，因此數發部成功向國發基金爭取匡列 100 億元，作為協助 AI 發展的政策性工具，並藉由「加強投資 AI 新創實施方案」，每年規劃 10 億元、期限 10年的模式，投資國內設立登記的 AI 新創企業。數發部預期，此方案將增加 1 萬人的就業機會，以及至少 20 家公司進入資本市場，有望創造新的兆元產業。\\\\n＊ 防堵中國零件化整為零，經濟部推國產車新制\\\\n為防止業者進口大量中國零組件，衝擊台灣汽車產業供應鏈，經濟部於今年 8 月 1 日開始實施新制，若國內車廠業者規劃引進中國品牌者等 4 種車款樣態，必須符合零件在地化採購比例，未來還須逐年提高占比，至於已上市車款也須要遵守相關規範。\\\\n產發署表示，今年 1 月 1 日至 7 月 31 日之前取得交通部安全審驗合格證的車款，其零件在地化比率須於明年 7 月 31 日達到 15% 以上；115 年 7 月 31 日要達到 25% 以上；115 年 8 月 1 日以後，同樣要達到 35% 以上。受到管制的 4 種車款樣態，包括陸資與國際品牌合資者、陸資併購的國際品牌者、國際品牌在中國廠生產者，以及單純中國品牌者。\\\\n＊ 製造業逾 66%，中國民營企業 500 強佔比再提升\\\\n根據中媒報導，中國全國工商聯日前發表 2024 民營企業 500 強榜單，其中製造業領域的公司數量，在營業收入的前 500 強中占 66.4%，占比連續 3 年出現提升。\\\\n中國全國工商聯所公開的榜單中，合計共有 9642 家企業，於 2023 年營業收入達人民幣 5 億元以上，京東集團以人民幣 1.08 兆元的營收規模，連續 3 年位列中國民營企業 500 強榜首；至於阿里巴巴與恆力集團則分列名列第二和第三。\\\\n【TechOrange 訊息公告】\\\\n親愛的讀者，感謝您一直以來對〈每日快訊 Top5〉的支持。我們將在 2024 年 10 月 21 日（一）暫停更新，未來您仍可以透過加入我們的官方\\xa0LINE 好友\\xa0掌握每日科技大事，並享有更豐富的內容與深入分析。我們期待能在不同平台與您繼續分享科技前沿資訊。\\\\n【推薦閱讀】\\\\n◆ 台積電若被摧毀全球產業倒退 15 年，分析師稱中國毀掉台積電將比保留更有利\\\\n◆ 半導體業惡夢又來了？分析師警告 AI 爆發將導致全球晶片短缺\\\\n◆ 打擊詐騙、降低人力成本都能靠 AI，專家指金融業將被 AI 重新塑造\\\\n＊本文開放合作夥伴轉載，資料來源：《華視新聞網》、《中央社》、《聯合報》、《中央社》2、《東方日報》。首圖來源：TSMC\"\\n    },\\n    {\\n        \"title\": \"【直攻排隊結帳痛點】「AI 計時器」讓店家月營收增 4%！背後用了什麼魔法？\",\\n        \"content\": \"撰文‧張如嫻\\\\n飛捷已是全球領先的 POS 機廠，卻不甘只做硬體，近年來積極發展軟體事業，將 AI 影像辨識技術導入美國速食業龍頭、東南亞連鎖超市，為集團事業開創第二春。\\\\n設計「AI 計時器」，店長緊盯螢幕調度人力\\\\n在這家位於美國華盛頓州的溫蒂漢堡（Wendy’s），店長一邊替客人打包餐點，一邊盯著牆上螢幕，原來，櫃檯的 AI 攝影機正追蹤每位客人的排隊、點餐和等餐時間，數字全顯示在螢幕上，一發現排隊時間變長，店長馬上調度人力，減少客人不耐而離開的機率，平均下來，讓月營收增加 4％。\\\\n很難想像，把這款「AI 計時器」系統導入速食業的，竟是原本只做硬體的工業電腦廠飛捷科技。\\\\n1984 年成立的飛捷專做 POS 機，約 8 成客戶來自全球零售、餐飲業，點餐、結帳機台全靠它。做了 30 幾年硬體，5 年前，飛捷走上軟體研發之路，還分拆出華捷智能（Berry AI）、英捷智能（Angible）、英諾菲三家純軟體子公司，前兩家更挾 AI 視覺辨識技術分別打進美國速食龍頭、東南亞大型連鎖超市，他們是如何做到的？\\\\n一家 POS 機大廠，為何切入 AI 影響辨識市場？\\\\n「這個產業做久了，就有一堆人進來，我們每天都在怕，會不會明年就被別人幹掉？」飛捷董事長林大成說，創業以來，他始終秉持「人多的地方不要去」，卻難抵擋後進者削價搶客，即使已拿下全球 POS 機大廠地位，對「被幹掉」的擔憂依然揮之不去，「每天都感受到這種壓力。」於是 2018 年，林大成決定發展「非 POS」業務，希望創造第二成長曲線，避開紅海競爭。\\\\n但問題馬上就來：不做 POS 機，還能做什麼？林大成把這項任務，交給剛自美國大學畢業的兒子林逸中。林逸中加入飛捷後，與同事從兩張桌子開始，發想 POS 機以外的新業務，「人多的地方不要去，但沒人的地方千萬不要去，你要跟在部隊旁邊走。」林大成時常這樣提醒林逸中，意思是，從大家都在做的生意中找到加值應用。\\\\n歷經峰迴路轉，終於找到適合的客群\\\\n他們從飛捷已打入的產業切入，注意到當時首次對外開幕的亞馬遜無人商店，號稱採用大量 AI 影像辨識技術，判斷消費者的動作與拿走的商品品項，激起林逸中研究 AI 影像辨識的興趣，並認為這項技術有商機。\\\\n2019 年，Berry AI 誕生，由飛捷 100％持股，年僅 25 歲的林逸中則擔任執行長，鎖定 AI 影像辨識找應用，飛捷正式跨入軟體市場；不過有技術又有經驗的人才稀缺，最初團隊只有 5 人，就走上這條與本業截然不同的路。\\\\nBerry AI 的「處女作」是麵包結帳機，也就是放在麵包店結帳櫃檯旁，代替店員辨識客人買了哪些麵包、計算價錢；然而麵包重疊、夾子遮擋等不確定因素太高，導致辨識準確率遲遲無法提升，就算一百個麵包中，AI 只會看錯一個，店員也無法接受。林逸中這才驚覺，不是所有客戶的痛點，自家技術都能解決。\\\\n第二次，Berry AI 轉換賽道，把影像辨識帶進郵局，自動量測包裹尺寸，結果公務機關導入新科技的速度慢，就連試用都要跑好幾個月的公文、招標流程，林逸中果斷放棄，並繼續研究其他產業應用。\\\\n歷經一年多峰迴路轉，某次林逸中在與好友聊天中，發現速食業者一直在尋找提升服務效率和品質的解方，他決定回頭鎖定飛捷最熟悉的餐飲客群。團隊經過訪談、調查得知，光是店內標準作業流程就有上百項，「業者對 AI 有非常多想像，一開始有 8、9 項功能，客戶全都想做。」林逸中舉例，業者會想知道員工上班有沒有滑手機、洗手有沒有洗乾淨、庫存盤點有沒有照實做，但是，Berry AI 得先幫他們挑出最適合用影像辨識、且最急迫的需求。\\\\n（閱讀全文…https://bit.ly/4gYGmjB）\\\\n【推薦閱讀】\\\\n◆ 不用排隊等結帳！Walmart 實驗新型態超市，手機掃商品拿了就走\\\\n◆ 7-Eleven 母公司重組業務，力抗加拿大超商巨頭收購\\\\n◆ Duolingo 的「情勒」通知討厭卻有用？拆解 2 大關鍵吸引破億月活躍用戶\\\\n＊本文經合作夥伴 今周刊 授權轉載，並同意 TechOrange 編寫導讀與修訂標題，原文標題為〈漢堡王、溫蒂都他客戶！25 歲二代帶領「40 年 POS 機大廠」攻 AI 影像辨識：客人少等 7 秒，營收成長 1%〉。首圖來源：生成式 AI 工具 Image Creater。\\\\n（責任編輯：廖紹伶）\\\\n今周刊延伸閱讀\\\\n◆ 全球趨勢調查》8 成台灣人為今天而活！人生成就感在於職場地位，最內捲國家前三名是他們\\\\n◆ 拿 500 萬存 0056，月領快 6 萬真能辦到？施昇輝：高息 ETF 這樣存「退休後放心花錢」\\\\n◆ 身價 4 億、年領 660 萬股息，88 歲神級散戶阿公卻說：只買高股息，遲早吃苦頭！6 大重點找出「會賺錢股票」\"\\n    },\\n    {\\n        \"title\": \"NVIDIA 股價創新高 逼近取代 Apple 成為全球最具價值公司\",\\n        \"content\": \"NVIDIA (NVDA.O) 的股價在週一以歷史最高價收盤，將這家 AI 芯片巨頭推向有望取代 Apple (AAPL.O) 成為全球最具價值公司的邊緣。隨著投資者對於其當前及下一代 AI 處理器的需求充滿信心，這家位於加州聖塔克拉拉的公司股價上漲了 2.4%，收於 138.07 美元。\\\\n早在六月，NVIDIA 一度成為全球最具價值的公司，但隨後被微軟超越。近幾個月來，這三大科技巨頭的市值一直相差無幾。最新的漲幅使 NVIDIA 的市值達到 3.39 兆美元，略低於 Apple 的 3.52 兆美元，且高於微軟的 3.12 兆美元。\\\\n在 Alphabet (GOOGL.O)、微軟、亞馬遜 (AMZN.O) 等主要科技公司競逐新興 AI 技術的賽事中，NVIDIA 成為華爾街最大的贏家。TD Cowen 分析師在週日的報告中表示：「我們認為，AI 領域的主要公司面臨的投資環境特徵類似於囚徒困境——每家公司都受到個人利益的驅動，繼續投入資金，否則將面臨潛在的毀滅性後果。」\\\\nTD Cowen 重申了對 NVIDIA 的 165 美元價格目標，稱其為「最佳選擇」，並指出該公司當前世代 AI 芯片的需求依然強勁。儘管 NVIDIA 在八月確認其即將推出的 Blackwell 芯片的生產提升將推遲至第四季，但公司淡化了此消息的影響，表示客戶仍在大量採購現有的芯片。\\\\n隨著投資者準備迎接季度財報季，Apple 股價上漲近 2%，微軟則上漲 0.7%，推動標準普爾 500 指數 (.SPX) 上漲 0.8%，創下新高。NVIDIA、Apple 和微軟合計約占標準普爾 500 指數的五分之一，對指數的日常漲跌具有重大影響。\\\\n台灣半導體製造公司 (2330.TW) 作為 NVIDIA 的合同生產商，預計將於週四報告季度利潤增長 40%，這得益於需求激增。根據 LSEG 的數據，分析師預計，AI 數據中心的擴建支出將使 NVIDIA 年度收入超過 1260 億美元，增長超過一倍。\\\\n儘管 NVIDIA 的漲勢將標準普爾 500 指數推向歷史新高，但投資者仍擔心，若出現 AI 技術支出減少的跡象，樂觀情緒可能會迅速消退。\\\\n本文開放合作夥伴轉載。資料來源：《Reuters》，首圖來源：Unsplash。\"\\n    },\\n    {\\n        \"title\": \"Netflix 用戶增長放緩，廣告收入成未來關鍵\",\\n        \"content\": \"Netflix 預計在本週四公布其六個季度以來最慢的用戶增長，這主要歸因於打擊共享密碼措施的效益逐漸減弱。分析師估計，Netflix 在 7 月至 9 月間新增了 400 萬用戶，包括原創影集《The Accident》及《The Perfect Couple》為美國熱播作品。然而，隨著用戶增長放緩，Netflix 開始將投資者的焦點轉向收入成長和利潤率，並計畫自 2025 年起停止公布訂閱數據。\\\\n該公司目前的廣告支持方案正在成長，但預期不會在 2026 年之前成為主要的成長動力。eMarketer 的 Ross Benes 表示，Netflix 在美國的廣告收入每年不到 10 億美元，這對他們的形象來說並不樂觀。一些分析師認為，Netflix 可能需要提高價格，並逐步取消更多無廣告方案，以促使更多用戶選擇廣告支持方案，因為這通常能為公司帶來更高的每用戶收入。\\\\nNetflix 早在去年 7 月便宣布停止向美國和英國新用戶提供每月 9.99 美元的無廣告基本方案，並逐步淘汰現有用戶的此方案。廣告支持方案每月收費 6.99 美元，而無廣告標準方案為 15.49 美元，價格自 2022 年起未作調整。\\\\n據分析師預估，Netflix 今年第三季的廣告收入將達 2.427 億美元，總收入增長 14.3%，達到 97.6 億美元。為吸引更多廣告商，該公司正專注於直播內容，包括 11 月的 Jake Paul 對 Mike Tyson 拳擊賽及 12 月的首場 NFL 賽事。此外，韓劇《魷魚遊戲》第二季將於 12 月上映，預計會在年底再度吸引大批用戶。\\\\nNetflix 的股價自 7 月公布第二季業績以來，已上漲 12.4%，遠高於標普 500 指數的 5% 漲幅。\\\\n本文開放合作夥伴轉載。資料來源：《Reuters》，首圖來源：Unsplash。\"\\n    },\\n    {\\n        \"title\": \"打擊詐騙、降低人力成本都能靠 AI，專家指金融業將被 AI 重新塑造\",\\n        \"content\": \"目前有越來越多金融服務公司，全都在宣傳 AI 能夠如何提高員工生產力，以及改進企業營運的整體效率，例如英國匯豐銀行就指出，人工智慧於金融業有著許多成功實例，產業專家甚至表明，未來 AI 將有能力重塑銀行面貌，推動金融產業朝新領域發展。\\\\n英國匯豐銀行生成式 AI 主管 Edward J Achtner 指出，目前公司在金融業務領域和職能中，擁有超過 550 個與 AI 相關的應用實例，比方說透過機器學習打擊洗錢和詐騙，並且為公司內部的知識工作者提供生成式 AI 系統等。\\\\n匯豐銀行與網路搜尋巨頭 Google 所建立的合作關係，主要就是關於利用 AI 技術防制洗錢和減少詐騙；Edward J Achtner 說，雙方合作已經持續好幾年，匯豐銀行最近也更深入地涉足生成式 AI 技術，藉此擁抱人工智慧。\\\\n金融業 AI 有 3 大應用，但推廣必須謹慎小心\\\\nEdward J Achtner 認為，即便 AI 應用在金融業取得成功的例子已經非常多，但是身為傳統業者，他們依然得冷靜進行取捨，即選擇透過 AI 做什麼，以及為哪些業務、領域導入 AI 功能。\\\\nEdward J Achtner 表示，生成式 AI 不同於其他人工智慧應用，兩者之間必須擁有明顯區隔；銀行業以非常謹慎的方式，處理跟生成式 AI 相關的任務，因為人工智慧雖然代表著許多機會和生產力收益，但同時也潛藏著多樣化的風險與威脅。\\\\n駿懋銀行（Lloyds）首席資料與分析官 Ranil Boteju 也指出，他們認為 AI 在金融業的主要應用有 3 種，第一是幕後工作的自動化，例如程式碼和工程文件撰寫；第二則是人機互動，比方說透過 AI 適時向對業務人員做出各種提醒；第三為客戶服務面，即藉由 AI 解答與回應顧客問題。\\\\nRanil Boteju 強調，駿懋銀行在向客戶提供生成式 AI 工具方面「謹慎行事」，並希望在真正開始擴展應用之前，先把限制護欄安裝到位；即便傳統銀行使用 AI、機器學習、智慧自動化和聊天機器人等類似服務，至今可能已有 15 到 20 年歷史，但生成式 AI 卻是更新、更加不同的技術。\\\\n金融創新業者更敢衝，用 AI 取代傳統人力\\\\n相對於傳統銀行業者，即使應用了 AI 卻仍維持保守作法，金融業其他公司，尤其是新創團隊的領導者，對於人工智慧投資所帶來的整體效率提升與成本下降，顯然有著更大膽的想法。\\\\n舉例而言，先買後付服務公司 Klarna 就指出，團隊一直都在利用人工智慧，彌補員工離職而導致勞動力減少與生產力損失。\\\\nKlarna 執行長 Sebastian Siemiatkowski 曾在今年 8 月表示，公司決定大範圍暫停招聘人類員工，並希望在 AI 的幫助下，將目前員工總數從 5000 人減少到 3800 人，裁員幅度達 24%，甚至於未來進一步減少到 2000 人，不過 Klarna 並未說明實現該目標的具體時間。\\\\nKlarna 發言人向外媒表示，公司從 AI 發展中看到的結果「非常真實」，之所以提早公布類似的裁員計畫，其實是因為 Klarna 希望誠實、透明的表達出，生成式 AI 對於公司及整個現實世界，究竟會造成多大衝擊。\\\\n金融 AI 科技成兩面刃，點到為止很關鍵\\\\n諮詢服務公司 NV Ltd 認為，Klarna 或許覺得 AI 可以使公司成為更有價值的企業，因此才把 AI 納入原有的裁員計畫；不過追根究柢，只要金融企業接受過適當的培訓，銀行業者還是能夠在不斷變化的 AI 時代重塑自己，幫助企業繼續前進發展。\\\\nING 集團首席分析官 Buckir Yilmaz 也表示，AI 不太可能像 Klarna 等新創公司所認為，可以為整體金融業帶來顛覆性改變。\\\\nBuckir Yilmaz 說，無論消費者或產業界，其實目前仍不需要由 AI 完全驅動的銀行服務，在許多流程當中，現有的流程與工具就已經足夠解決問題，且因為生成式 AI 過於強大，甚至帶有潛在的破壞性，銀行不見得需要全部採用。\\\\n瑞典網路支付公司 Trustly 執行長 Johan Tjarnberg 抱持著同樣想法，他認為 AI 是線上支付領域最大的技術槓桿之一，即便如此，公司也會更專注於人工智慧的基礎知識，而不是由 AI 所主導的客戶服務變革。\\\\n【推薦閱讀】\\\\n◆ 支付巨頭 Paypal 看似走出低潮，前高層分析 2 大因素仍落後蘋果、Google\\\\n◆ 「預測市場」平台在金融界熱度竄升！為何狂吸大咖投資，還被用來預測選舉？\\\\n◆ 從 21 小時縮短到 4 小時，台新銀未來將用 AI 寫徵信報告\\\\n＊本文開放合作夥伴轉載，資料來源：《CNBC》、《CogX》。首圖來源：Pxhere\"\\n    },\\n    {\\n        \"title\": \"改善工業能源效率從何做起？報告揭 3 大行動每年全球一起省下 2 兆美元\",\\n        \"content\": \"PwC 發布《2024 淨零排放經濟指數報告》，指出全球減碳速度停滯，與前一年度相較，2023 年全球碳密集度降幅僅 1.02%，為十年來最低水準。\\\\nPwC 表示，若要將全球暖化限制在1.5°C，須以目前 20 倍的速度減碳；其中，G7 國家更需在 2030 年前加速淘汰煤炭、終止化石燃料補貼，擴大對再生能源和能源效率的投資；此外，企業若採取三大面向行動，有望降低能源密集度，與全球共同省下數兆美元。\\\\n化石燃料仍為主要能源，導致碳排量上升\\\\n化石燃料仍是目前主要的能源來源，2023 年化石燃料使用量年成長 1.5%，導致耗用每單位能源的碳排量上升。PwC 表示，產業結構、基礎設施、能源政策與技術發展程度，影響各國減碳幅度，2023 年七大工業國組織（G7）碳密集度降幅為 5.31%，而新興七國（E7）碳密集度上升 0.04%，顯示新興市場仰賴化石燃料發展工業化與都市化，仍在努力平衡經濟成長與減碳目標。\\\\nG7 國家碳密集度，雖然降幅在 2023 年達到 5.31%，但過去五年年均降幅僅 3.45%，與 2019 年水準相比，預估 2030 年碳排放量將減少 19% 至 33%，仍遠低於巴黎協定目標所需的 58% 減排量。因此，PwC 認為為縮小差距，G7 國家需在 2030 年前加速淘汰煤炭、終止化石燃料補貼，擴大對再生能源和能源效率的投資。\\\\n再生能源方面，根據國際能源署（IEA）統計，2023 年再生能源裝置容量新增 510 GW，約四分之三的成長來自太陽能，主要集中於亞太地區、美國、歐洲、巴西，中國大陸占新裝機裝置容量六成。以目前再生能源占總發電來源的比例來看，水力發電占 6%，風電占 4%、太陽能占 2%，地熱、生質燃料合計約占 2%。\\\\nPwC 觀察，由於各國政策支持、太陽能與風電技術成本下降，使 2023 年再生能源裝置容量再創新高，總裝置容量增加 14%，達到 3,870 GW，並有望在未來五年內成長一倍，於 2025 年超過煤炭成為全球主要電力來源。根據 COP28 協議，2030 年前全球再生能源裝置容量需累計至少 11,000 GW，能源效率年均改善率提升至 4%以上。\\\\n電力需求快速成長！提升「馬達」效率可減少能源密集度\\\\n疫情後能源需求反彈，2023 年全球能源消耗上升 2.02%。部分 G20 國家雖然耗用每單位能源的碳排放量下降，能源消耗量卻增加，顯示能源「供應面」處於能源轉型，而能源「使用面」的減量卻相當有限。\\\\nPwC 指出，科技進步將有助於重塑能源使用的方式、改善能源效率，例如智慧電網、優化發電技術，AI 能源管理系統等。\\\\n其中，馬達用電占工業用電超過六成，PwC 與世界經濟論壇（WEF）合作研究預估，隨著各國法規逐步提升馬達效率標準的要求，可減少單一工業製程 90% 能源密集度（每單位 GDP 耗用能源），若廣泛應用，工業部門的能源密集度可望較目前減少 29%。\\\\n此外，AI 技術則可預測電力供需，優化電網管理與調度；也可即時分析交通數據，規劃較省油的行車路線。\\\\n企業啟動 3 大行動，全球有望每年節省 2 兆美元\\\\nPwC 與 WEF 合作研究發現，企業若啟動「節能」、「提升能源效率」、「與價值鏈合作」等三大面向行動，2030 年全球可望降低 31% 能源密集度，每年節省 2 兆美元。此仰賴政府與企業共同努力，擴大跨產業、供應鏈和公部門的廣泛合作，推動鼓勵降低能源密集度的政策。\\\\n不過，PwC 也提醒，需要留意的是 AI 本身亦消耗大量能源。IEA 預估，至 2026 年，資料中心、AI 和加密貨幣等耗電量將翻倍。在推動新科技應用的同時，也須加強對再生能源和提升能源效率的投資，避免新科技應用使能源問題惡化。\\\\n此外，氣候調適（Climate adaptation，針對當前氣候變化或是預期影響而調適的過程）可能增加能源消耗，如海水淡化、建築空調等皆消耗大量能源，各國應透過制定採購推動技術創新和提高能源效率產品或服務的政策，減少氣候變遷的負面影響，同時避免不當調適增加長期氣候風險。\\\\nPwC 表示，全球暖化不只危害環境，更持續影響企業獲利能力，面對氣候變遷的挑戰，企業必須評估法規及消費者行為的變化如何對營運方式產生影響，並重新將氣候風險及機會整合至營運策略。\\\\n【推薦閱讀】\\\\n◆ WEF 「燈塔工廠」公布！鴻海揭拿下 2 座燈塔工廠背後關鍵技術\\\\n◆ 全球工業機器人數量破 420 萬！IFR 看好 2 大因素推未來成長\\\\n◆ 製造商提供「維修權」必要嗎？一場義肢送修爭議帶你看為何是消費者權益\\\\n＊本文由 PwC 提供，內文與標題經 TechOrange 修訂後刊登。新聞稿／產品訊息提供，可寄至：[email\\xa0protected]，經編輯檯審核並評估合宜性後再行刊登。首圖來源：Unsplash。\\\\n（責任編輯：廖紹伶）\"\\n    }\\n]', mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5c466f",
   "metadata": {},
   "source": [
    "方法Ａ：\n",
    "```\n",
    "# 1. 解析成 Nodes\n",
    "parser = JSONNodeParser()\n",
    "nodes = parser.get_nodes_from_documents(documents)\n",
    "\n",
    "# 2. 直接用 nodes 建立索引 (注意這裡沒有 .from_documents)\n",
    "index = VectorStoreIndex(nodes, embed_model=embed_model)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351dbc0b",
   "metadata": {},
   "source": [
    "方法Ｂ：\n",
    "```\n",
    "from llama_index.core.node_parser import JSONNodeParser\n",
    "\n",
    "parser = JSONNodeParser()\n",
    "\n",
    "# 在建立時指定 transformations\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    embed_model=embed_model,\n",
    "    transformations=[parser]  # 指定使用你的 JSON Parser\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0fb882",
   "metadata": {},
   "source": [
    ". 總結：我該選哪一個？\n",
    "- 如果你希望流程透明：選 方法 A。你自己手動跑一次 parser.get_nodes_from_documents(documents)，你可以順便 print(len(nodes)) 看看檔案被切成了幾塊，心裡比較踏實。\n",
    "\n",
    "- 如果你追求程式碼簡潔：選 方法 B。這是在 LlamaIndex 新版本中更推薦的做法，它把「切分」和「索引」整合在一個流水線中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde5100e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
