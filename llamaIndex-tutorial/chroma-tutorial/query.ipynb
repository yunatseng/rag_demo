{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8b3c586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from llama_index.core import VectorStoreIndex, StorageContext, SimpleDirectoryReader\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core.node_parser import JSONNodeParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9448d170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-m3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af8cf1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 0. è®€å–åŸå§‹è³‡æ–™ ===\n",
    "# ç¢ºä¿è·¯å¾‘æ­£ç¢ºï¼ŒæŒ‡å‘ä½ å­˜æ”¾ JSON çš„è³‡æ–™å¤¾\n",
    "documents = SimpleDirectoryReader(input_dir=\"../data/json\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2160cb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. åˆå§‹åŒ– JSON Parser ===\n",
    "parser = JSONNodeParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a37a97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. é€£æ¥è³‡æ–™åº«\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "collection_name = \"my_json_collection\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954fb761",
   "metadata": {},
   "source": [
    "# === ğŸ’€ æ¯€æ»…æ­¥é©Ÿï¼šåˆªé™¤èˆŠçš„é‡è¤‡è³‡æ–™ ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5714b22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—‘ï¸ æˆåŠŸåˆªé™¤èˆŠçš„ Collection 'my_json_collection'ï¼Œæº–å‚™é‡å»º...\n"
     ]
    }
   ],
   "source": [
    "# === ğŸ’€ æ¯€æ»…æ­¥é©Ÿï¼šåˆªé™¤èˆŠçš„é‡è¤‡è³‡æ–™ ===\n",
    "try:\n",
    "    db.delete_collection(collection_name)\n",
    "    print(f\"ğŸ—‘ï¸ æˆåŠŸåˆªé™¤èˆŠçš„ Collection '{collection_name}'ï¼Œæº–å‚™é‡å»º...\")\n",
    "except Exception as e:\n",
    "    print(\"æŸ¥ç„¡æ­¤ Collectionï¼Œå¯èƒ½æ˜¯ç¬¬ä¸€æ¬¡åŸ·è¡Œï¼Œç›´æ¥ç¹¼çºŒã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9996016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. è¨­å®š ChromaDB æŒä¹…åŒ–å±¤ ===\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(\n",
    "    \"my_json_collection\", \n",
    "    metadata={\"hnsw:space\": \"cosine\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6d72e1",
   "metadata": {},
   "source": [
    "### ç‰¹åˆ¥è£œå……ï¼šä½ ç”¨çš„ BGE-M3 å¾ˆå¼·\n",
    "ä½ æ­£åœ¨ä½¿ç”¨çš„ Embedding æ¨¡å‹ BAAI/bge-m3 å…¶å¯¦æœ¬èº«å°±æ˜¯ç‚ºäº† æ··åˆæª¢ç´¢ è¨­è¨ˆçš„ï¼\n",
    "\n",
    "M3 çš„æ„æ€ï¼šMulti-Linguality (å¤šèªè¨€), Multi-Granularity (å¤šç²’åº¦), Multi-Functionality (å¤šåŠŸèƒ½)ã€‚\n",
    "\n",
    "å®ƒåŒæ™‚æ”¯æ´ Dense Vector (åƒ HNSW ç”¨) å’Œ Sparse Vector (åƒ BM25 ç”¨)ã€‚\n",
    "\n",
    "ä¸éï¼Œè¦åœ¨ LlamaIndex ä¸­å®Œå…¨ç™¼æ® BGE-M3 çš„ã€ŒåŸç”Ÿã€æ··åˆèƒ½åŠ›æ¯”è¼ƒé€²éšï¼ˆéœ€è¦ç‰¹å®šçš„ Retriever è¨­å®šï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7f7e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3. å»ºç«‹ Vector Store å’Œ Storage Context ===\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e83d0dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é€™è£¡æœƒè‡ªå‹•ï¼šè®€å– documents -> ç”¨ parser åˆ‡åˆ† -> è½‰å‘é‡ -> å­˜å…¥ chroma_db\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    embed_model=embed_model,\n",
    "    transformations=[parser] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9c6c2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆåŠŸè™•ç† 1 ä»½æ–‡ä»¶ï¼Œç´¢å¼•å·²å„²å­˜è‡³ chroma_db\n"
     ]
    }
   ],
   "source": [
    "print(f\"æˆåŠŸè™•ç† {len(documents)} ä»½æ–‡ä»¶ï¼Œç´¢å¼•å·²å„²å­˜è‡³ chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9309401",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "`llama-index-llms-openai` package not found, please run `pip install llama-index-llms-openai`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages/llama_index/core/llms/utils.py:36\u001b[0m, in \u001b[0;36mresolve_llm\u001b[0;34m(llm, callback_manager)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI  \u001b[38;5;66;03m# pants: no-infer-dep\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     38\u001b[0m         validate_openai_api_key,\n\u001b[1;32m     39\u001b[0m     )  \u001b[38;5;66;03m# pants: no-infer-dep\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama_index.llms.openai'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# === 5. æ¸¬è©¦æŸ¥è©¢ ===\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_query_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m response \u001b[38;5;241m=\u001b[39m query_engine\u001b[38;5;241m.\u001b[39mquery(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mé€™ä»½è³‡æ–™é—œæ–¼ä»€éº¼ï¼Ÿ\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages/llama_index/core/indices/base.py:378\u001b[0m, in \u001b[0;36mBaseIndex.as_query_engine\u001b[0;34m(self, llm, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquery_engine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretriever_query_engine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    371\u001b[0m     RetrieverQueryEngine,\n\u001b[1;32m    372\u001b[0m )\n\u001b[1;32m    374\u001b[0m retriever \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_retriever(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    375\u001b[0m llm \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    376\u001b[0m     resolve_llm(llm, callback_manager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_manager)\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m llm\n\u001b[0;32m--> 378\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mSettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\n\u001b[1;32m    379\u001b[0m )\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m RetrieverQueryEngine\u001b[38;5;241m.\u001b[39mfrom_args(\n\u001b[1;32m    382\u001b[0m     retriever,\n\u001b[1;32m    383\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    385\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages/llama_index/core/settings.py:36\u001b[0m, in \u001b[0;36m_Settings.llm\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the LLM.\"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm \u001b[38;5;241m=\u001b[39m \u001b[43mresolve_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefault\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm\u001b[38;5;241m.\u001b[39mcallback_manager \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_manager\n",
      "File \u001b[0;32m~/Documents/python_rag_class/demo_1/.venv/lib/python3.11/site-packages/llama_index/core/llms/utils.py:44\u001b[0m, in \u001b[0;36mresolve_llm\u001b[0;34m(llm, callback_manager)\u001b[0m\n\u001b[1;32m     42\u001b[0m     validate_openai_api_key(llm\u001b[38;5;241m.\u001b[39mapi_key)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`llama-index-llms-openai` package not found, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease run `pip install llama-index-llms-openai`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     47\u001b[0m     )\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m******\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not load OpenAI model. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m******\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m     )\n",
      "\u001b[0;31mImportError\u001b[0m: `llama-index-llms-openai` package not found, please run `pip install llama-index-llms-openai`"
     ]
    }
   ],
   "source": [
    "# === 5. æ¸¬è©¦æŸ¥è©¢ ===\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"é€™ä»½è³‡æ–™é—œæ–¼ä»€éº¼ï¼Ÿ\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c3e84f",
   "metadata": {},
   "source": [
    "å„ªåŒ–ï¼š\n",
    "```\n",
    "import chromadb\n",
    "import os\n",
    "from llama_index.core import VectorStoreIndex, StorageContext, SimpleDirectoryReader\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core.node_parser import JSONNodeParser\n",
    "\n",
    "# === 1. è¨­å®šç’°å¢ƒèˆ‡åƒæ•¸ ===\n",
    "# ç¢ºä¿é€™äº›è®Šæ•¸è·Ÿä¹‹å‰ä¸€æ¨£\n",
    "input_dir = \"./data/json\"\n",
    "persist_dir = \"./chroma_db\"\n",
    "collection_name = \"my_json_collection\"\n",
    "\n",
    "# åˆå§‹åŒ– Parser\n",
    "parser = JSONNodeParser()\n",
    "\n",
    "# === 2. é€£æ¥ ChromaDB ===\n",
    "db = chromadb.PersistentClient(path=persist_dir)\n",
    "\n",
    "# å–å¾— Collection\n",
    "chroma_collection = db.get_or_create_collection(\n",
    "    collection_name,\n",
    "    metadata={\"hnsw:space\": \"cosine\"}\n",
    ")\n",
    "\n",
    "# è¨­å®š Storage Context\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# === 3. æ ¸å¿ƒé‚è¼¯ï¼šåˆ¤æ–·è¦ã€Œè¼‰å…¥ã€é‚„æ˜¯ã€Œæ–°å»ºã€ ===\n",
    "# æª¢æŸ¥ç›®å‰ Collection è£¡é¢æœ‰å¹¾ç­†è³‡æ–™\n",
    "doc_count = chroma_collection.count()\n",
    "\n",
    "if doc_count > 0:\n",
    "    print(f\"âœ… åµæ¸¬åˆ°è³‡æ–™åº«å·²æœ‰ {doc_count} ç­†è³‡æ–™ï¼Œç›´æ¥è¼‰å…¥ç´¢å¼•ï¼ˆä¸æ¶ˆè€— Token/æ™‚é–“ï¼‰...\")\n",
    "    \n",
    "    # ç›´æ¥å¾ Vector Store è¼‰å…¥ç´¢å¼•\n",
    "    # æ³¨æ„ï¼šé€™è£¡ä¸éœ€è¦å‚³å…¥ documentsï¼Œä¹Ÿä¸éœ€è¦ parser\n",
    "    index = VectorStoreIndex.from_vector_store(\n",
    "        vector_store,\n",
    "        embed_model=embed_model,\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ è³‡æ–™åº«ç‚ºç©ºï¼Œé–‹å§‹è®€å–æª”æ¡ˆä¸¦è¨ˆç®— Embedding (é€™æœƒèŠ±ä¸€é»æ™‚é–“)...\")\n",
    "    \n",
    "    # 1. è®€å–æª”æ¡ˆ\n",
    "    documents = SimpleDirectoryReader(input_dir=input_dir).load_data()\n",
    "    \n",
    "    # 2. å»ºç«‹æ–°ç´¢å¼•ä¸¦å­˜å…¥\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        documents,\n",
    "        storage_context=storage_context, # æŒ‡å‘æˆ‘å€‘çš„ Chroma\n",
    "        embed_model=embed_model,\n",
    "        transformations=[parser]         # åˆ‡åˆ† JSON\n",
    "    )\n",
    "    print(\"ğŸ‰ ç´¢å¼•å»ºç«‹å®Œæˆä¸¦å·²å„²å­˜ï¼\")\n",
    "\n",
    "# === 4. æ¸¬è©¦æŸ¥è©¢ ===\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"é€™ä»½è³‡æ–™é—œæ–¼ä»€éº¼ï¼Ÿ\")\n",
    "print(\"-\" * 20)\n",
    "print(response)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ded13e",
   "metadata": {},
   "source": [
    "## Retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe335fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever()\n",
    "result = retriever.retrieve(\"nvidia è‚¡åƒ¹å‰µæ–°é«˜å½±éŸ¿ï¼Ÿ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b182a10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a945f76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_path': '/Users/dingtseng/Documents/python_rag_class/demo_1/llamaIndex-tutorial/chroma-tutorial/../data/json/techorange-2024-10-16.json',\n",
       " 'file_name': 'techorange-2024-10-16.json',\n",
       " 'file_type': 'application/json',\n",
       " 'file_size': 40751,\n",
       " 'creation_date': '2025-12-18',\n",
       " 'last_modified_date': '2025-01-03'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "793ccf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 1727c12f-8cf5-48e3-ad65-d93abe360a0e\n",
      "Text: title NVIDIA è‚¡åƒ¹å‰µæ–°é«˜ é€¼è¿‘å–ä»£ Apple æˆç‚ºå…¨çƒæœ€å…·åƒ¹å€¼å…¬å¸ content NVIDIA (NVDA.O)\n",
      "çš„è‚¡åƒ¹åœ¨é€±ä¸€ä»¥æ­·å²æœ€é«˜åƒ¹æ”¶ç›¤ï¼Œå°‡é€™å®¶ AI èŠ¯ç‰‡å·¨é ­æ¨å‘æœ‰æœ›å–ä»£ Apple (AAPL.O)\n",
      "æˆç‚ºå…¨çƒæœ€å…·åƒ¹å€¼å…¬å¸çš„é‚Šç·£ã€‚éš¨è‘—æŠ•è³‡è€…å°æ–¼å…¶ç•¶å‰åŠä¸‹ä¸€ä»£ AI è™•ç†å™¨çš„éœ€æ±‚å……æ»¿ä¿¡å¿ƒï¼Œé€™å®¶ä½æ–¼åŠ å·è–å¡”å…‹æ‹‰æ‹‰çš„å…¬å¸è‚¡åƒ¹ä¸Šæ¼²äº† 2.4%ï¼Œæ”¶æ–¼\n",
      "138.07 ç¾å…ƒã€‚ æ—©åœ¨å…­æœˆï¼ŒNVIDIA\n",
      "ä¸€åº¦æˆç‚ºå…¨çƒæœ€å…·åƒ¹å€¼çš„å…¬å¸ï¼Œä½†éš¨å¾Œè¢«å¾®è»Ÿè¶…è¶Šã€‚è¿‘å¹¾å€‹æœˆä¾†ï¼Œé€™ä¸‰å¤§ç§‘æŠ€å·¨é ­çš„å¸‚å€¼ä¸€ç›´ç›¸å·®ç„¡å¹¾ã€‚æœ€æ–°çš„æ¼²å¹…ä½¿ NVIDIA çš„å¸‚å€¼é”åˆ° 3.39\n",
      "å…†ç¾å…ƒï¼Œç•¥ä½æ–¼ Apple çš„ 3.52 å…†ç¾å…ƒï¼Œä¸”é«˜æ–¼å¾®è»Ÿçš„ 3.12 å…†ç¾å…ƒã€‚ åœ¨ Alphabet\n",
      "(GOOGL.O)ã€å¾®è»Ÿã€äºé¦¬éœ...\n",
      "Score:  0.737\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc092c3c",
   "metadata": {},
   "source": [
    "## TIPS: metadata æœ‰ filters å¯ä»¥å»éæ¿¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79dba505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** e4673b4c-1829-4e27-8476-eb8fd482cf17<br>**Similarity:** 0.6511675945653475<br>**Text:** title NVIDIA è‚¡åƒ¹å‰µæ–°é«˜ é€¼è¿‘å–ä»£ Apple æˆç‚ºå…¨çƒæœ€å…·åƒ¹å€¼å…¬å¸\n",
       "content NVIDIA (NVDA.O) çš„è‚¡åƒ¹åœ¨é€±ä¸€ä»¥æ­·å²æœ€é«˜åƒ¹æ”¶ç›¤ï¼Œå°‡é€™å®¶ AI èŠ¯ç‰‡å·¨é ­æ¨å‘æœ‰æœ›å–ä»£...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** b8a977b8-f370-46d4-932d-d9a335719a0d<br>**Similarity:** 0.5830028371838138<br>**Text:** title Netflix ç”¨æˆ¶å¢é•·æ”¾ç·©ï¼Œå»£å‘Šæ”¶å…¥æˆæœªä¾†é—œéµ\n",
       "content Netflix é è¨ˆåœ¨æœ¬é€±å››å…¬å¸ƒå…¶å…­å€‹å­£åº¦ä»¥ä¾†æœ€æ…¢çš„ç”¨æˆ¶å¢é•·ï¼Œé€™ä¸»è¦æ­¸å› æ–¼æ‰“æ“Šå…±äº«å¯†ç¢¼æªæ–½çš„æ•ˆç›Šé€æ¼¸æ¸›å¼±ã€‚åˆ†æå¸«ä¼°è¨ˆ...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** e603a11c-5ad5-49c7-8318-7e8421340e62<br>**Similarity:** 0.5808336162390303<br>**Text:** title æ”¹å–„å·¥æ¥­èƒ½æºæ•ˆç‡å¾ä½•åšèµ·ï¼Ÿå ±å‘Šæ­ 3 å¤§è¡Œå‹•æ¯å¹´å…¨çƒä¸€èµ·çœä¸‹ 2 å…†ç¾å…ƒ\n",
       "content PwC ç™¼å¸ƒã€Š2024 æ·¨é›¶æ’æ”¾ç¶“æ¿ŸæŒ‡æ•¸å ±å‘Šã€‹ï¼ŒæŒ‡å‡ºå…¨çƒæ¸›ç¢³é€Ÿåº¦åœæ»¯ï¼Œèˆ‡å‰ä¸€å¹´åº¦ç›¸è¼ƒï¼Œ202...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "retriever = index.as_retriever(similarity_top_k=3)\n",
    "retrieved_nodes = retriever.retrieve(\"è‚¡åƒ¹å‰µæ–°é«˜å½±éŸ¿ï¼Ÿ\")\n",
    "\n",
    "for node in retrieved_nodes:\n",
    "    display_source_node(node, source_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0684d3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç›®å‰ç´¢å¼•ä¸­çš„ç¸½ç¯€é»æ•¸: 0\n"
     ]
    }
   ],
   "source": [
    "# æª¢æŸ¥ç›®å‰ç´¢å¼•ä¸­çš„ç¸½ç¯€é»æ•¸\n",
    "print(f\"ç›®å‰ç´¢å¼•ä¸­çš„ç¸½ç¯€é»æ•¸: {len(index.docstore.docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7f946e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è³‡æ–™åº«çœŸå¯¦ç¯€é»æ•¸: 10\n"
     ]
    }
   ],
   "source": [
    "# ç›´æ¥å• ChromaDB è£¡é¢å­˜äº†å¹¾ç­†\n",
    "print(f\"è³‡æ–™åº«çœŸå¯¦ç¯€é»æ•¸: {chroma_collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c4333fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è³‡æ–™åº«ä¸­çš„ ID åˆ—è¡¨: ['127c494a-0d89-45af-8d4b-ccc8cd1da5e9', 'e855b72a-cd97-4cf5-a3e6-d6ea6f613067', '9c7f32e2-df22-494f-935f-fa2a84571de0', '4a61673f-2203-4cd9-8ca5-69fd45e4da86', '99edec4b-0ccd-40d4-80bb-2659c25c572c', '027b5c5d-042f-4551-9d6a-d44739ab8386', 'e4673b4c-1829-4e27-8476-eb8fd482cf17', 'b8a977b8-f370-46d4-932d-d9a335719a0d', '3c1e7ff4-3f18-424e-bc65-6f875473d00f', 'e603a11c-5ad5-49c7-8318-7e8421340e62']\n"
     ]
    }
   ],
   "source": [
    "print(f\"è³‡æ–™åº«ä¸­çš„ ID åˆ—è¡¨: {chroma_collection.get()['ids']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "582c4bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç¸½å…±æœ‰ 10 ç­†è³‡æ–™\n",
      "\n",
      "--- Node 1 ---\n",
      "title ã€å°ç£é™·å…¥å°·å°¬è™•å¢ƒã€‘åŠå°é«”è€—é›»é‡ç‹‚é£†åˆå¾—æ·¨é›¶è½‰å‹ï¼Œæ ¸é›»æœƒæ˜¯æœ€ä½³è§£ï¼Ÿ\n",
      "content å°ç£ä¼æ¥­æ»¿è¶³äº†å…¨çƒé«˜é” 68% çš„æ™¶ç‰‡è£½é€ ä¾›æ‡‰ï¼Œéš¨ä¹‹è€Œä¾†çš„æ˜¯å¤§é‡èƒ½æºéœ€æ±‚â€”â€”æ ¹æ“šç¶ è‰²å’Œå¹³çµ„ç¹”çš„é æ¸¬ï¼Œ20\n",
      "\n",
      "--- Node 2 ---\n",
      "title Google ç°½ä¸‹å”è­°è²·æ ¸é›»ï¼Œå»º 7 åº§å°å‹åæ‡‰çˆç‚º AI èˆ‡ç’°ä¿éœ€æ±‚\n",
      "content Google å®£å¸ƒèˆ‡èƒ½æºæ–°å‰µå…¬å¸ Kairos Power ç°½ä¸‹å”è­°ï¼Œå°‡æ–¼æœªä¾†èˆˆå»º 7 åº§å°å‹æ¨¡çµ„åŒ–\n",
      "\n",
      "--- Node 3 ---\n",
      "title è˜‹æœç­–ç•¥å¤§è½‰å½ï¼Ÿå‚³æ”¾æ£„æ¯å¹´æ›´æ–°ç”¢å“ï¼ŒVR æŒ«æ•—è€ƒæ…®æ¨æ™ºæ…§çœ¼é¡\n",
      "content æ ¹æ“šè˜‹æœè¨˜è€… Mark Gurman è¿‘ä¾†çš„çˆ†æ–™ï¼Œä»–æŒ‡å‡ºè˜‹æœæ­£åœ¨è€ƒæ…®æ”¾æ£„æ¯å¹´æ›´æ–°æ——ä¸‹ç”¢å“ï¼Œä¸å†å¼·åˆ¶éµå®ˆåŸå…ˆçš„å‡\n",
      "\n",
      "--- Node 4 ---\n",
      "title ã€ç¢³è²»ä¸Šè·¯ã€‘å…¨åœ‹å¾µæ”¶å°è±¡é” 500 å®¶ï¼æ”¿åºœæ‰“ç®—æ€éº¼ä½¿ç”¨æ”¶åˆ°çš„ 60 å„„ï¼Ÿ\n",
      "content ç’°å¢ƒéƒ¨é•·å½­å•Ÿæ˜ 14 æ—¥åˆ°ç«‹æ³•é™¢ç¤¾ç¦ç’°è¡›å§”å“¡æœƒå°ˆé¡Œå ±å‘Šã€Œå°ç£çš„ç¢³è²»æ”¶è²»æ¨™æº–æ±ºè­°ã€ï¼Œæœƒä¸­æœ‰å¤šä½ç«‹å§”\n",
      "\n",
      "--- Node 5 ---\n",
      "title ã€10/15 å¿«è¨Š Top 5ã€‘å°ç©é›»ç¨±ã€Œæ²’æœ‰æ–°è¨ˆç•«ã€å¦èªæ­æ´²æ“´å» ï¼Œå°‡å°ˆæ³¨ç•¶å‰å…¨çƒä½ˆå±€\n",
      "content ä»Šå¤©ï¼Œã€ŠTechOrangeã€‹åŒæ¨£ç²¾é¸å‡º 5 å‰‡åœ‹å…§å¤–ç§‘æŠ€æ–°èå¤§äº‹ï¼Œè®“ä½ æŒæ¡ç§‘æŠ€å‹•æ…‹\n",
      "\n",
      "--- Node 6 ---\n",
      "title ã€ç›´æ”»æ’éšŠçµå¸³ç—›é»ã€‘ã€ŒAI è¨ˆæ™‚å™¨ã€è®“åº—å®¶æœˆç‡Ÿæ”¶å¢ 4%ï¼èƒŒå¾Œç”¨äº†ä»€éº¼é­”æ³•ï¼Ÿ\n",
      "content æ’°æ–‡â€§å¼µå¦‚å«»\n",
      "é£›æ·å·²æ˜¯å…¨çƒé ˜å…ˆçš„ POS æ©Ÿå» ï¼Œå»ä¸ç”˜åªåšç¡¬é«”ï¼Œè¿‘å¹´ä¾†ç©æ¥µç™¼å±•è»Ÿé«”äº‹æ¥­ï¼Œå°‡ A\n",
      "\n",
      "--- Node 7 ---\n",
      "title NVIDIA è‚¡åƒ¹å‰µæ–°é«˜ é€¼è¿‘å–ä»£ Apple æˆç‚ºå…¨çƒæœ€å…·åƒ¹å€¼å…¬å¸\n",
      "content NVIDIA (NVDA.O) çš„è‚¡åƒ¹åœ¨é€±ä¸€ä»¥æ­·å²æœ€é«˜åƒ¹æ”¶ç›¤ï¼Œå°‡é€™å®¶ AI èŠ¯ç‰‡å·¨é ­æ¨å‘æœ‰æœ›å–ä»£ Ap\n",
      "\n",
      "--- Node 8 ---\n",
      "title Netflix ç”¨æˆ¶å¢é•·æ”¾ç·©ï¼Œå»£å‘Šæ”¶å…¥æˆæœªä¾†é—œéµ\n",
      "content Netflix é è¨ˆåœ¨æœ¬é€±å››å…¬å¸ƒå…¶å…­å€‹å­£åº¦ä»¥ä¾†æœ€æ…¢çš„ç”¨æˆ¶å¢é•·ï¼Œé€™ä¸»è¦æ­¸å› æ–¼æ‰“æ“Šå…±äº«å¯†ç¢¼æªæ–½çš„æ•ˆç›Šé€æ¼¸æ¸›å¼±ã€‚åˆ†æå¸«ä¼°è¨ˆï¼ŒNe\n",
      "\n",
      "--- Node 9 ---\n",
      "title æ‰“æ“Šè©é¨™ã€é™ä½äººåŠ›æˆæœ¬éƒ½èƒ½é  AIï¼Œå°ˆå®¶æŒ‡é‡‘èæ¥­å°‡è¢« AI é‡æ–°å¡‘é€ \n",
      "content ç›®å‰æœ‰è¶Šä¾†è¶Šå¤šé‡‘èæœå‹™å…¬å¸ï¼Œå…¨éƒ½åœ¨å®£å‚³ AI èƒ½å¤ å¦‚ä½•æé«˜å“¡å·¥ç”Ÿç”¢åŠ›ï¼Œä»¥åŠæ”¹é€²ä¼æ¥­ç‡Ÿé‹çš„æ•´é«”æ•ˆç‡ï¼Œä¾‹å¦‚\n",
      "\n",
      "--- Node 10 ---\n",
      "title æ”¹å–„å·¥æ¥­èƒ½æºæ•ˆç‡å¾ä½•åšèµ·ï¼Ÿå ±å‘Šæ­ 3 å¤§è¡Œå‹•æ¯å¹´å…¨çƒä¸€èµ·çœä¸‹ 2 å…†ç¾å…ƒ\n",
      "content PwC ç™¼å¸ƒã€Š2024 æ·¨é›¶æ’æ”¾ç¶“æ¿ŸæŒ‡æ•¸å ±å‘Šã€‹ï¼ŒæŒ‡å‡ºå…¨çƒæ¸›ç¢³é€Ÿåº¦åœæ»¯ï¼Œèˆ‡å‰ä¸€å¹´åº¦ç›¸è¼ƒï¼Œ2023 å¹´\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = chroma_collection.get()\n",
    "\n",
    "print(f\"ç¸½å…±æœ‰ {len(data['ids'])} ç­†è³‡æ–™\\n\")\n",
    "\n",
    "for i, text in enumerate(data['documents'][:20]):\n",
    "    print(f\"--- Node {i+1} ---\")\n",
    "    # åªå°å‡ºå‰ 50 å€‹å­—é¿å…æ´—ç‰ˆ\n",
    "    print(text[:100]) \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534cef68",
   "metadata": {},
   "source": [
    "### å‘ï¼šå¦‚æœé‡è¤‡å­˜äº†ï¼Œï½‹å°±æœƒå¤±æ•ˆï¼Œå› ç‚ºretriveræœƒè‡ªå‹•éæ¿¾åˆ†æ•¸å®Œå…¨ä¸€æ¨¡ä¸€æ¨£çš„æ–‡ç« "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a21cb7",
   "metadata": {},
   "source": [
    "## query\n",
    "å¦‚æœç”¨ index.as_query_engine å°±ä¸ç”¨è‡ªå·±æ‰‹å‹• retrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9a23959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "llm = Ollama(model=\"gemma3:12b\", request_timeout=600.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef0d8dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA è‚¡åƒ¹å‰µæ–°é«˜å°‡æ¨™æº–æ™®çˆ¾ 500 æŒ‡æ•¸æ¨å‘æ­·å²æ–°é«˜ï¼Œä¸” NVIDIAã€Apple å’Œå¾®è»Ÿåˆè¨ˆç´„å æ¨™æº–æ™®çˆ¾ 500 æŒ‡æ•¸çš„äº”åˆ†ä¹‹ä¸€ï¼Œå°æŒ‡æ•¸çš„æ—¥å¸¸æ¼²è·Œå…·æœ‰é‡å¤§å½±éŸ¿ã€‚\n",
      "[NodeWithScore(node=TextNode(id_='e4673b4c-1829-4e27-8476-eb8fd482cf17', embedding=None, metadata={'file_path': '/Users/dingtseng/Documents/python_rag_class/demo_1/llamaIndex-tutorial/chroma-tutorial/../data/json/techorange-2024-10-16.json', 'file_name': 'techorange-2024-10-16.json', 'file_type': 'application/json', 'file_size': 40751, 'creation_date': '2025-12-18', 'last_modified_date': '2025-01-03'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c622f256-d402-4a67-8eb5-4bda6ebdfa34', node_type='4', metadata={'file_path': '/Users/dingtseng/Documents/python_rag_class/demo_1/llamaIndex-tutorial/chroma-tutorial/../data/json/techorange-2024-10-16.json', 'file_name': 'techorange-2024-10-16.json', 'file_type': 'application/json', 'file_size': 40751, 'creation_date': '2025-12-18', 'last_modified_date': '2025-01-03'}, hash='d6f6a62104ba541eaff2940e8e272aa0c9b987fa113f897eeceb7ba55c5a8208'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='027b5c5d-042f-4551-9d6a-d44739ab8386', node_type='1', metadata={'file_path': '/Users/dingtseng/Documents/python_rag_class/demo_1/llamaIndex-tutorial/chroma-tutorial/../data/json/techorange-2024-10-16.json', 'file_name': 'techorange-2024-10-16.json', 'file_type': 'application/json', 'file_size': 40751, 'creation_date': '2025-12-18', 'last_modified_date': '2025-01-03'}, hash='e2771e1612ed6f81de446b6f4973b6373aa976a6b3abbc1cf0fbb012910d64a0'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='b8a977b8-f370-46d4-932d-d9a335719a0d', node_type='1', metadata={}, hash='9007ee6ef685a2a7df4e10aacb1bc205f6005cf0657f4a81b1205ac2a38482db')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='title NVIDIA è‚¡åƒ¹å‰µæ–°é«˜ é€¼è¿‘å–ä»£ Apple æˆç‚ºå…¨çƒæœ€å…·åƒ¹å€¼å…¬å¸\\ncontent NVIDIA (NVDA.O) çš„è‚¡åƒ¹åœ¨é€±ä¸€ä»¥æ­·å²æœ€é«˜åƒ¹æ”¶ç›¤ï¼Œå°‡é€™å®¶ AI èŠ¯ç‰‡å·¨é ­æ¨å‘æœ‰æœ›å–ä»£ Apple (AAPL.O) æˆç‚ºå…¨çƒæœ€å…·åƒ¹å€¼å…¬å¸çš„é‚Šç·£ã€‚éš¨è‘—æŠ•è³‡è€…å°æ–¼å…¶ç•¶å‰åŠä¸‹ä¸€ä»£ AI è™•ç†å™¨çš„éœ€æ±‚å……æ»¿ä¿¡å¿ƒï¼Œé€™å®¶ä½æ–¼åŠ å·è–å¡”å…‹æ‹‰æ‹‰çš„å…¬å¸è‚¡åƒ¹ä¸Šæ¼²äº† 2.4%ï¼Œæ”¶æ–¼ 138.07 ç¾å…ƒã€‚\\næ—©åœ¨å…­æœˆï¼ŒNVIDIA ä¸€åº¦æˆç‚ºå…¨çƒæœ€å…·åƒ¹å€¼çš„å…¬å¸ï¼Œä½†éš¨å¾Œè¢«å¾®è»Ÿè¶…è¶Šã€‚è¿‘å¹¾å€‹æœˆä¾†ï¼Œé€™ä¸‰å¤§ç§‘æŠ€å·¨é ­çš„å¸‚å€¼ä¸€ç›´ç›¸å·®ç„¡å¹¾ã€‚æœ€æ–°çš„æ¼²å¹…ä½¿ NVIDIA çš„å¸‚å€¼é”åˆ° 3.39 å…†ç¾å…ƒï¼Œç•¥ä½æ–¼ Apple çš„ 3.52 å…†ç¾å…ƒï¼Œä¸”é«˜æ–¼å¾®è»Ÿçš„ 3.12 å…†ç¾å…ƒã€‚\\nåœ¨ Alphabet (GOOGL.O)ã€å¾®è»Ÿã€äºé¦¬éœ (AMZN.O) ç­‰ä¸»è¦ç§‘æŠ€å…¬å¸ç«¶é€æ–°èˆˆ AI æŠ€è¡“çš„è³½äº‹ä¸­ï¼ŒNVIDIA æˆç‚ºè¯çˆ¾è¡—æœ€å¤§çš„è´å®¶ã€‚TD Cowen åˆ†æå¸«åœ¨é€±æ—¥çš„å ±å‘Šä¸­è¡¨ç¤ºï¼šã€Œæˆ‘å€‘èªç‚ºï¼ŒAI é ˜åŸŸçš„ä¸»è¦å…¬å¸é¢è‡¨çš„æŠ•è³‡ç’°å¢ƒç‰¹å¾µé¡ä¼¼æ–¼å›šå¾’å›°å¢ƒâ€”â€”æ¯å®¶å…¬å¸éƒ½å—åˆ°å€‹äººåˆ©ç›Šçš„é©…å‹•ï¼Œç¹¼çºŒæŠ•å…¥è³‡é‡‘ï¼Œå¦å‰‡å°‡é¢è‡¨æ½›åœ¨çš„æ¯€æ»…æ€§å¾Œæœã€‚ã€\\nTD Cowen é‡ç”³äº†å° NVIDIA çš„ 165 ç¾å…ƒåƒ¹æ ¼ç›®æ¨™ï¼Œç¨±å…¶ç‚ºã€Œæœ€ä½³é¸æ“‡ã€ï¼Œä¸¦æŒ‡å‡ºè©²å…¬å¸ç•¶å‰ä¸–ä»£ AI èŠ¯ç‰‡çš„éœ€æ±‚ä¾ç„¶å¼·å‹ã€‚å„˜ç®¡ NVIDIA åœ¨å…«æœˆç¢ºèªå…¶å³å°‡æ¨å‡ºçš„ Blackwell èŠ¯ç‰‡çš„ç”Ÿç”¢æå‡å°‡æ¨é²è‡³ç¬¬å››å­£ï¼Œä½†å…¬å¸æ·¡åŒ–äº†æ­¤æ¶ˆæ¯çš„å½±éŸ¿ï¼Œè¡¨ç¤ºå®¢æˆ¶ä»åœ¨å¤§é‡æ¡è³¼ç¾æœ‰çš„èŠ¯ç‰‡ã€‚\\néš¨è‘—æŠ•è³‡è€…æº–å‚™è¿æ¥å­£åº¦è²¡å ±å­£ï¼ŒApple è‚¡åƒ¹ä¸Šæ¼²è¿‘ 2%ï¼Œå¾®è»Ÿå‰‡ä¸Šæ¼² 0.7%ï¼Œæ¨å‹•æ¨™æº–æ™®çˆ¾ 500 æŒ‡æ•¸ (.SPX) ä¸Šæ¼² 0.8%ï¼Œå‰µä¸‹æ–°é«˜ã€‚NVIDIAã€Apple å’Œå¾®è»Ÿåˆè¨ˆç´„å æ¨™æº–æ™®çˆ¾ 500 æŒ‡æ•¸çš„äº”åˆ†ä¹‹ä¸€ï¼Œå°æŒ‡æ•¸çš„æ—¥å¸¸æ¼²è·Œå…·æœ‰é‡å¤§å½±éŸ¿ã€‚\\nå°ç£åŠå°é«”è£½é€ å…¬å¸ (2330.TW) ä½œç‚º NVIDIA çš„åˆåŒç”Ÿç”¢å•†ï¼Œé è¨ˆå°‡æ–¼é€±å››å ±å‘Šå­£åº¦åˆ©æ½¤å¢é•· 40%ï¼Œé€™å¾—ç›Šæ–¼éœ€æ±‚æ¿€å¢ã€‚æ ¹æ“š LSEG çš„æ•¸æ“šï¼Œåˆ†æå¸«é è¨ˆï¼ŒAI æ•¸æ“šä¸­å¿ƒçš„æ“´å»ºæ”¯å‡ºå°‡ä½¿ NVIDIA å¹´åº¦æ”¶å…¥è¶…é 1260 å„„ç¾å…ƒï¼Œå¢é•·è¶…éä¸€å€ã€‚\\nå„˜ç®¡ NVIDIA çš„æ¼²å‹¢å°‡æ¨™æº–æ™®çˆ¾ 500 æŒ‡æ•¸æ¨å‘æ­·å²æ–°é«˜ï¼Œä½†æŠ•è³‡è€…ä»æ“”å¿ƒï¼Œè‹¥å‡ºç¾ AI æŠ€è¡“æ”¯å‡ºæ¸›å°‘çš„è·¡è±¡ï¼Œæ¨‚è§€æƒ…ç·’å¯èƒ½æœƒè¿…é€Ÿæ¶ˆé€€ã€‚\\næœ¬æ–‡é–‹æ”¾åˆä½œå¤¥ä¼´è½‰è¼‰ã€‚è³‡æ–™ä¾†æºï¼šã€ŠReutersã€‹ï¼Œé¦–åœ–ä¾†æºï¼šUnsplashã€‚', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7373100070099398), NodeWithScore(node=TextNode(id_='b8a977b8-f370-46d4-932d-d9a335719a0d', embedding=None, metadata={'file_path': '/Users/dingtseng/Documents/python_rag_class/demo_1/llamaIndex-tutorial/chroma-tutorial/../data/json/techorange-2024-10-16.json', 'file_name': 'techorange-2024-10-16.json', 'file_type': 'application/json', 'file_size': 40751, 'creation_date': '2025-12-18', 'last_modified_date': '2025-01-03'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c622f256-d402-4a67-8eb5-4bda6ebdfa34', node_type='4', metadata={'file_path': '/Users/dingtseng/Documents/python_rag_class/demo_1/llamaIndex-tutorial/chroma-tutorial/../data/json/techorange-2024-10-16.json', 'file_name': 'techorange-2024-10-16.json', 'file_type': 'application/json', 'file_size': 40751, 'creation_date': '2025-12-18', 'last_modified_date': '2025-01-03'}, hash='d6f6a62104ba541eaff2940e8e272aa0c9b987fa113f897eeceb7ba55c5a8208'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='e4673b4c-1829-4e27-8476-eb8fd482cf17', node_type='1', metadata={'file_path': '/Users/dingtseng/Documents/python_rag_class/demo_1/llamaIndex-tutorial/chroma-tutorial/../data/json/techorange-2024-10-16.json', 'file_name': 'techorange-2024-10-16.json', 'file_type': 'application/json', 'file_size': 40751, 'creation_date': '2025-12-18', 'last_modified_date': '2025-01-03'}, hash='891e4b02eb88675371ce63ae7f0781ab53f1fdeef21ea1b91fd5bdf2ea2b40ec'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='3c1e7ff4-3f18-424e-bc65-6f875473d00f', node_type='1', metadata={}, hash='b3b541ce43fb9c64e4e23a8b4bb4ee91d7a28d407e71f222d0de0b8932f61b8c')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='title Netflix ç”¨æˆ¶å¢é•·æ”¾ç·©ï¼Œå»£å‘Šæ”¶å…¥æˆæœªä¾†é—œéµ\\ncontent Netflix é è¨ˆåœ¨æœ¬é€±å››å…¬å¸ƒå…¶å…­å€‹å­£åº¦ä»¥ä¾†æœ€æ…¢çš„ç”¨æˆ¶å¢é•·ï¼Œé€™ä¸»è¦æ­¸å› æ–¼æ‰“æ“Šå…±äº«å¯†ç¢¼æªæ–½çš„æ•ˆç›Šé€æ¼¸æ¸›å¼±ã€‚åˆ†æå¸«ä¼°è¨ˆï¼ŒNetflix åœ¨ 7 æœˆè‡³ 9 æœˆé–“æ–°å¢äº† 400 è¬ç”¨æˆ¶ï¼ŒåŒ…æ‹¬åŸå‰µå½±é›†ã€ŠThe Accidentã€‹åŠã€ŠThe Perfect Coupleã€‹ç‚ºç¾åœ‹ç†±æ’­ä½œå“ã€‚ç„¶è€Œï¼Œéš¨è‘—ç”¨æˆ¶å¢é•·æ”¾ç·©ï¼ŒNetflix é–‹å§‹å°‡æŠ•è³‡è€…çš„ç„¦é»è½‰å‘æ”¶å…¥æˆé•·å’Œåˆ©æ½¤ç‡ï¼Œä¸¦è¨ˆç•«è‡ª 2025 å¹´èµ·åœæ­¢å…¬å¸ƒè¨‚é–±æ•¸æ“šã€‚\\nè©²å…¬å¸ç›®å‰çš„å»£å‘Šæ”¯æŒæ–¹æ¡ˆæ­£åœ¨æˆé•·ï¼Œä½†é æœŸä¸æœƒåœ¨ 2026 å¹´ä¹‹å‰æˆç‚ºä¸»è¦çš„æˆé•·å‹•åŠ›ã€‚eMarketer çš„ Ross Benes è¡¨ç¤ºï¼ŒNetflix åœ¨ç¾åœ‹çš„å»£å‘Šæ”¶å…¥æ¯å¹´ä¸åˆ° 10 å„„ç¾å…ƒï¼Œé€™å°ä»–å€‘çš„å½¢è±¡ä¾†èªªä¸¦ä¸æ¨‚è§€ã€‚ä¸€äº›åˆ†æå¸«èªç‚ºï¼ŒNetflix å¯èƒ½éœ€è¦æé«˜åƒ¹æ ¼ï¼Œä¸¦é€æ­¥å–æ¶ˆæ›´å¤šç„¡å»£å‘Šæ–¹æ¡ˆï¼Œä»¥ä¿ƒä½¿æ›´å¤šç”¨æˆ¶é¸æ“‡å»£å‘Šæ”¯æŒæ–¹æ¡ˆï¼Œå› ç‚ºé€™é€šå¸¸èƒ½ç‚ºå…¬å¸å¸¶ä¾†æ›´é«˜çš„æ¯ç”¨æˆ¶æ”¶å…¥ã€‚\\nNetflix æ—©åœ¨å»å¹´ 7 æœˆä¾¿å®£å¸ƒåœæ­¢å‘ç¾åœ‹å’Œè‹±åœ‹æ–°ç”¨æˆ¶æä¾›æ¯æœˆ 9.99 ç¾å…ƒçš„ç„¡å»£å‘ŠåŸºæœ¬æ–¹æ¡ˆï¼Œä¸¦é€æ­¥æ·˜æ±°ç¾æœ‰ç”¨æˆ¶çš„æ­¤æ–¹æ¡ˆã€‚å»£å‘Šæ”¯æŒæ–¹æ¡ˆæ¯æœˆæ”¶è²» 6.99 ç¾å…ƒï¼Œè€Œç„¡å»£å‘Šæ¨™æº–æ–¹æ¡ˆç‚º 15.49 ç¾å…ƒï¼Œåƒ¹æ ¼è‡ª 2022 å¹´èµ·æœªä½œèª¿æ•´ã€‚\\næ“šåˆ†æå¸«é ä¼°ï¼ŒNetflix ä»Šå¹´ç¬¬ä¸‰å­£çš„å»£å‘Šæ”¶å…¥å°‡é” 2.427 å„„ç¾å…ƒï¼Œç¸½æ”¶å…¥å¢é•· 14.3%ï¼Œé”åˆ° 97.6 å„„ç¾å…ƒã€‚ç‚ºå¸å¼•æ›´å¤šå»£å‘Šå•†ï¼Œè©²å…¬å¸æ­£å°ˆæ³¨æ–¼ç›´æ’­å…§å®¹ï¼ŒåŒ…æ‹¬ 11 æœˆçš„ Jake Paul å° Mike Tyson æ‹³æ“Šè³½åŠ 12 æœˆçš„é¦–å ´ NFL è³½äº‹ã€‚æ­¤å¤–ï¼ŒéŸ“åŠ‡ã€Šé­·é­šéŠæˆ²ã€‹ç¬¬äºŒå­£å°‡æ–¼ 12 æœˆä¸Šæ˜ ï¼Œé è¨ˆæœƒåœ¨å¹´åº•å†åº¦å¸å¼•å¤§æ‰¹ç”¨æˆ¶ã€‚\\nNetflix çš„è‚¡åƒ¹è‡ª 7 æœˆå…¬å¸ƒç¬¬äºŒå­£æ¥­ç¸¾ä»¥ä¾†ï¼Œå·²ä¸Šæ¼² 12.4%ï¼Œé é«˜æ–¼æ¨™æ™® 500 æŒ‡æ•¸çš„ 5% æ¼²å¹…ã€‚\\næœ¬æ–‡é–‹æ”¾åˆä½œå¤¥ä¼´è½‰è¼‰ã€‚è³‡æ–™ä¾†æºï¼šã€ŠReutersã€‹ï¼Œé¦–åœ–ä¾†æºï¼šUnsplashã€‚', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.6028750778552528)]\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(llm=llm)\n",
    "response = query_engine.query(\"nvidia è‚¡åƒ¹å‰µæ–°é«˜å½±éŸ¿ï¼Ÿ\")\n",
    "print(response) # ???\n",
    "print(response.source_nodes) # æŸ¥çœ‹æª¢ç´¢æ™‚ç”¨äº†å“ªäº›ç¯€é»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf70be10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Response: NVIDIA è‚¡åƒ¹å‰µæ–°é«˜å°‡æ¨™æº–æ™®çˆ¾ 500 æŒ‡æ•¸æ¨å‘æ­·å²æ–°é«˜ï¼Œä¸” NVIDIAã€Apple\n",
      "å’Œå¾®è»Ÿåˆè¨ˆç´„å æ¨™æº–æ™®çˆ¾ 500 æŒ‡æ•¸çš„äº”åˆ†ä¹‹ä¸€ï¼Œå°æŒ‡æ•¸çš„æ—¥å¸¸æ¼²è·Œå…·æœ‰é‡å¤§å½±éŸ¿ã€‚\n",
      "______________________________________________________________________\n",
      "Source Node 1/2\n",
      "Node ID: e4673b4c-1829-4e27-8476-eb8fd482cf17\n",
      "Similarity: 0.7373100070099398\n",
      "Text: title NVIDIA è‚¡åƒ¹å‰µæ–°é«˜ é€¼è¿‘å–ä»£ Apple æˆç‚ºå…¨çƒæœ€å…·åƒ¹å€¼å…¬å¸ content NVIDIA (NVDA.O)\n",
      "çš„è‚¡åƒ¹åœ¨é€±ä¸€ä»¥æ­·å²æœ€é«˜åƒ¹æ”¶ç›¤ï¼Œå°‡é€™å®¶ AI èŠ¯ç‰‡å·¨é ­æ¨å‘æœ‰æœ›å–ä»£...\n",
      "______________________________________________________________________\n",
      "Source Node 2/2\n",
      "Node ID: b8a977b8-f370-46d4-932d-d9a335719a0d\n",
      "Similarity: 0.6028750778552528\n",
      "Text: title Netflix ç”¨æˆ¶å¢é•·æ”¾ç·©ï¼Œå»£å‘Šæ”¶å…¥æˆæœªä¾†é—œéµ content Netflix\n",
      "é è¨ˆåœ¨æœ¬é€±å››å…¬å¸ƒå…¶å…­å€‹å­£åº¦ä»¥ä¾†æœ€æ…¢çš„ç”¨æˆ¶å¢é•·ï¼Œé€™ä¸»è¦æ­¸å› æ–¼æ‰“æ“Šå…±äº«å¯†ç¢¼æªæ–½çš„æ•ˆç›Šé€æ¼¸æ¸›å¼±ã€‚åˆ†æå¸«ä¼°è¨ˆ...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31måœ¨ç›®å‰å„²å­˜æ ¼æˆ–ä¸Šä¸€å€‹å„²å­˜æ ¼ä¸­åŸ·è¡Œç¨‹å¼ç¢¼æ™‚ï¼ŒKernel å·²ææ¯€ã€‚\n",
      "\u001b[1;31mè«‹æª¢é–±å„²å­˜æ ¼ä¸­çš„ç¨‹å¼ç¢¼ï¼Œæ‰¾å‡ºå¤±æ•—çš„å¯èƒ½åŸå› ã€‚\n",
      "\u001b[1;31må¦‚éœ€è©³ç´°è³‡è¨Šï¼Œè«‹æŒ‰ä¸€ä¸‹<a href='https://aka.ms/vscodeJupyterKernelCrash'>é€™è£¡</a>ã€‚\n",
      "\u001b[1;31må¦‚éœ€è©³ç´°è³‡æ–™ï¼Œè«‹æª¢è¦– Jupyter <a href='command:jupyter.viewOutput'>è¨˜éŒ„</a>ã€‚"
     ]
    }
   ],
   "source": [
    "from llama_index.core.response.pprint_utils import pprint_response\n",
    "pprint_response(response, show_source=True, source_length=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
